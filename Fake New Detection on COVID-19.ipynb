{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c5bda9",
   "metadata": {},
   "source": [
    "# Preprocessing and Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b845b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545da9a1",
   "metadata": {},
   "source": [
    "## Read in raw data and Search the sentiment dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2986cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'raw_data/TG.csv'\n",
    "df = pd.read_csv(file, encoding='utf-8')\n",
    "dict_df = pd.read_csv('inquirerbasic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = dict_df[dict_df['Positiv'].notnull()]['Entry'].str.lower().tolist()\n",
    "negative_words = dict_df[dict_df['Negativ'].notnull()]['Entry'].str.lower().tolist()\n",
    "strong_words = dict_df[dict_df['Strong'].notnull()]['Entry'].str.lower().tolist()\n",
    "weak_words = dict_df[dict_df['Weak'].notnull()]['Entry'].str.lower().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_positive_words(body):\n",
    "    # Check if body is not a string (it could be nan or a number)\n",
    "    if not isinstance(body, str):\n",
    "        return 0\n",
    "    \n",
    "    # Remove punctuation and convert the body to lowercase\n",
    "    body = body.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the body\n",
    "    tokens = word_tokenize(body)\n",
    "    \n",
    "    # Count the positive words\n",
    "    return sum(token in positive_words for token in tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a89b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_negative_words(body):\n",
    "    # Check if body is not a string (it could be nan or a number)\n",
    "    if not isinstance(body, str):\n",
    "        return 0\n",
    "    \n",
    "    # Remove punctuation and convert the body to lowercase\n",
    "    body = body.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the body\n",
    "    tokens = word_tokenize(body)\n",
    "    \n",
    "    # Count the negative words\n",
    "    return sum(token in negative_words for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_strong_words(body):\n",
    "    # Check if body is not a string (it could be nan or a number)\n",
    "    if not isinstance(body, str):\n",
    "        return 0\n",
    "    \n",
    "    # Remove punctuation and convert the body to lowercase\n",
    "    body = body.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the body\n",
    "    tokens = word_tokenize(body)\n",
    "    \n",
    "    # Count the strong words\n",
    "    return sum(token in strong_words for token in tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35bd4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_weak_words(body):\n",
    "    # Check if body is not a string (it could be nan or a number)\n",
    "    if not isinstance(body, str):\n",
    "        return 0\n",
    "    \n",
    "    # Remove punctuation and convert the body to lowercase\n",
    "    body = body.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the body\n",
    "    tokens = word_tokenize(body)\n",
    "    \n",
    "    # Count the weak words\n",
    "    return sum(token in weak_words for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a660eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'positive_word_count' to the DataFrame\n",
    "df['positive_word_count'] = df['body'].apply(count_positive_words)\n",
    "# Add a new column 'negative_word_count' to the DataFrame\n",
    "df['negative_word_count'] = df['body'].apply(count_negative_words)\n",
    "df['strong_word_count'] = df['body'].apply(count_strong_words)\n",
    "df['weak_word_count'] = df['body'].apply(count_weak_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d671a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['positive_score'] = df['positive_word_count'] / df['length']\n",
    "# df['negative_score'] = df['negative_word_count'] / df['length']\n",
    "# df['strong_score'] = df['strong_word_count'] / df['length']\n",
    "# df['weak_score'] = df['weak_word_count'] / df['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_drop = ['positive_word_count', 'negative_word_count', 'strong_word_count', 'weak_word_count']\n",
    "# df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "df.to_csv('TG_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750c9ec",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe727efb",
   "metadata": {},
   "source": [
    "### News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = pd.read_csv('processed_data/NYT_processed.csv')\n",
    "columns_to_drop = ['section', 'body', 'subject', 'title']\n",
    "\n",
    "# drop NA values\n",
    "nyt.dropna(inplace=True)\n",
    "\n",
    "# drop the unnecessary columns\n",
    "nyt.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# convert the 'date' column to datetime format\n",
    "nyt['date'] = pd.to_datetime(nyt['date'])\n",
    "\n",
    "# sort the dataframe by date\n",
    "nyt.sort_values('date', inplace=True)\n",
    "\n",
    "nyt\n",
    "\n",
    "# check if there are any duplicated items\n",
    "# any_duplicates = nyt['date'].duplicated().any()\n",
    "\n",
    "# print(any_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f140881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = pd.read_csv('processed_data/TG_processed.csv')\n",
    "columns_to_drop = ['section', 'body', 'subject', 'title']\n",
    "\n",
    "# drop NA values\n",
    "tg.dropna(inplace=True)\n",
    "\n",
    "# drop the unnecessary columns\n",
    "tg.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# convert the 'date' column to datetime format\n",
    "tg['date'] = pd.to_datetime(tg['date'])\n",
    "\n",
    "# sort the dataframe by date\n",
    "tg.sort_values('date', inplace=True)\n",
    "\n",
    "tg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.read_csv('processed_data/TIMES_processed.csv', encoding='latin-1')\n",
    "columns_to_drop = ['section', 'body', 'subject', 'title']\n",
    "\n",
    "# drop NA values\n",
    "times.dropna(inplace=True)\n",
    "\n",
    "# drop the unnecessary columns\n",
    "times.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# convert the 'date' column to datetime format\n",
    "times['date'] = pd.to_datetime(times['date'])\n",
    "\n",
    "# sort the dataframe by date\n",
    "times.sort_values('date', inplace=True)\n",
    "\n",
    "times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b946099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = pd.read_csv('processed_data/CD_processed.csv')\n",
    "columns_to_drop = ['body', 'subject', 'title']\n",
    "cd.dropna(inplace=True)\n",
    "cd.drop(columns=columns_to_drop, inplace=True)\n",
    "cd['date'] = pd.to_datetime(cd['date'])\n",
    "cd.sort_values('date', inplace=True)\n",
    "cd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140c89c",
   "metadata": {},
   "source": [
    "### Stock Exchange Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1b19f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nyse = pd.read_csv('raw_data/NYSE_index.csv')\n",
    "nyse['Date'] = pd.to_datetime(nyse['Date'])\n",
    "nyse.info()\n",
    "nyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f46c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse['Daily_return'] = nyse['Close'].pct_change()\n",
    "nyse['Trend'] = np.where(nyse['Daily_return'] > 0, 'UP', 'DOWN')\n",
    "nyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0fadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_duration(trend_column):\n",
    "    trend_duration = [1]  # Start with 1 for the first day\n",
    "    for i in range(1, len(trend_column)):\n",
    "        if trend_column[i] == trend_column[i-1]:  # If the trend is the same as the previous day's\n",
    "            trend_duration.append(trend_duration[i-1] + 1)  # Add 1 to the previous day's count\n",
    "        else:  # If the trend changed\n",
    "            trend_duration.append(1)  # Start a new count\n",
    "    return trend_duration\n",
    "\n",
    "# Apply the function to the 'Trend' column\n",
    "nyse['Trend_duration'] = trend_duration(nyse['Trend'].tolist())\n",
    "nyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed NYSE index data\n",
    "nyse.to_csv('nyse_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = pd.read_csv('raw_data/SSE_index.csv')\n",
    "sse['Date'] = pd.to_datetime(sse['Date'])\n",
    "sse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da077e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse['Daily_return'] = sse['Close'].pct_change()\n",
    "sse['Trend'] = np.where(sse['Daily_return'] > 0, 'UP', 'DOWN')\n",
    "sse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222562c",
   "metadata": {},
   "source": [
    "# Simple Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f6a4e",
   "metadata": {},
   "source": [
    "## DA on news reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e880f",
   "metadata": {},
   "source": [
    "### Descriptive Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba068e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "result = pd.read_csv('cleaned_INFO.csv')\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a4222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# average lengths of different publications\n",
    "avg_length = result.groupby('source')['length'].mean()\n",
    "avg_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bbfc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variation\n",
    "var_length = result.groupby('source')['length'].std()\n",
    "var_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8240e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the maximum report length for each source\n",
    "max_length = result.groupby('source')['length'].max()\n",
    "\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d431243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the minimum report length for each source\n",
    "min_length = result.groupby('source')['length'].min()\n",
    "\n",
    "min_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import zscore\n",
    "\n",
    "# # Compute the z-scores for the 'length' column\n",
    "# result['length_zscore'] = result.groupby('source')['length'].transform(zscore)\n",
    "\n",
    "# # result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of reports from each source for each date\n",
    "counts = result.groupby(['source', 'date']).size().reset_index(name='count')\n",
    "\n",
    "# Filter the DataFrame to only show the rows where 'report_count' is more than 1\n",
    "duplicated = counts[counts['count'] > 1]\n",
    "\n",
    "# Print the result\n",
    "duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a8fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_up = result.groupby(['date', 'source']).sum()\n",
    "sum_up = sum_up.reset_index()\n",
    "sum_up.to_csv('processed_INFO.csv')\n",
    "sum_up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb9088",
   "metadata": {},
   "source": [
    "### Content Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1253b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_up['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f243f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_up.groupby('source')['length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Histogram\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(sum_up['length'], bins=30, kde=True)\n",
    "plt.title('Distribution of Report Lengths')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12458aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='source', y='length', data=sum_up)\n",
    "plt.title('Report Lengths by Source')\n",
    "plt.xlabel('Source')\n",
    "plt.ylabel('Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b46fd4",
   "metadata": {},
   "source": [
    "### Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99683314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend of report length over time\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(x='date', y='length', data=sum_up)\n",
    "plt.title('Trend of Report Length Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Length')\n",
    "plt.show()\n",
    "\n",
    "# Trend of report length over time for each source\n",
    "df_grouped = sum_up.groupby(['date', 'source'])['length'].mean().reset_index()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(x='date', y='length', hue='source', data=df_grouped)\n",
    "plt.title('Trend of Report Length Over Time for Each Source')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Length')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average sentiment by source\n",
    "source_sentiments = sum_up.groupby('source')[['positive_word_count', 'negative_word_count']].mean()\n",
    "print(source_sentiments)\n",
    "\n",
    "# Plot\n",
    "source_sentiments.plot(kind='bar', stacked=True)\n",
    "plt.title('Average Sentiment by Source')\n",
    "plt.xlabel('Source')\n",
    "plt.ylabel('Average Word Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "correlation_matrix = sum_up.corr()\n",
    "correlation_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot positive_word_count over time\n",
    "sum_up.groupby('date')['positive_word_count'].mean().plot()\n",
    "plt.title('Average Positive Word Count Over Time')\n",
    "plt.ylabel('Average Positive Word Count')\n",
    "plt.show()\n",
    "\n",
    "# Plot negative_word_count over time\n",
    "sum_up.groupby('date')['negative_word_count'].mean().plot()\n",
    "plt.title('Average Negative Word Count Over Time')\n",
    "plt.ylabel('Average Negative Word Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a424afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "# Autocorrelation plot for the report length\n",
    "autocorrelation_plot(sum_up['length'])\n",
    "plt.title('Autocorrelation Plot for Report Length')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ad55f",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66e465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_up['positive_score'] = sum_up['positive_word_count']/sum_up['length']\n",
    "sum_up['negative_score'] = sum_up['negative_word_count']/sum_up['length']\n",
    "sum_up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf62e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores_by_source = sum_up.groupby('source')[['positive_score', 'negative_score']].mean()\n",
    "average_scores_by_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbe1568",
   "metadata": {},
   "source": [
    "## DA on stock exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny = pd.read_csv('nyse_processed.csv', index_col=0)\n",
    "ny['Date'] = pd.to_datetime(ny['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d05f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# about daily return\n",
    "std_dev = ny['Daily_return'].std()\n",
    "mean_return = ny['Daily_return'].mean()\n",
    "skewness = ny['Daily_return'].skew()\n",
    "kurtosis = ny['Daily_return'].kurtosis()\n",
    "max_return = ny['Daily_return'].max()\n",
    "min_return = ny['Daily_return'].min()\n",
    "\n",
    "print('max:', max_return)\n",
    "print('min:', min_return)\n",
    "print('kurtosis:', kurtosis)\n",
    "print('skewness:', skewness)\n",
    "print('mean_return:', mean_return)\n",
    "print('std_dev:', std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-5 day correlation\n",
    "for i in range(1, 6):\n",
    "    lagged_returns = ny['Daily_return'].shift(i)\n",
    "    correlation = ny['Daily_return'].corr(lagged_returns.dropna())  # Remove missing values before calculating correlation\n",
    "    print(f'Correlation of Daily Return with {i}-day Lag: {correlation}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657aaae2",
   "metadata": {},
   "source": [
    "### Time Series Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ffdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLose\n",
    "ny.set_index('Date', inplace=True)\n",
    "ny['Close'].plot(figsize=(14, 7))\n",
    "\n",
    "plt.title('Stock Closing Price Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c165ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily return\n",
    "ny['Daily_return'].plot(figsize=(14, 7))\n",
    "\n",
    "plt.title('Stock Closing Price Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bb0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = ny.corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "# Autocorrelation plot for the report length\n",
    "autocorrelation_plot(ny['Close'])\n",
    "plt.title('Autocorrelation Plot for Close price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ee3e2e",
   "metadata": {},
   "source": [
    "## Grouped Analysis(join news dataset and stock dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f4a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5aebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_without_cd = sum_up[sum_up['source'] != 'China Daily']\n",
    "news_without_cd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f84f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = news_without_cd.drop(columns=['source','positive_score','negative_score'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa2ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_dates = df[df['date'].duplicated(keep=False)]\n",
    "duplicated_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd163e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby('date').agg({\n",
    "    'length': 'sum',\n",
    "    'positive_word_count': 'sum',\n",
    "    'negative_word_count': 'sum',\n",
    "    'strong_word_count':'sum',\n",
    "    'weak_word_count':'sum'\n",
    "}).reset_index()\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b38dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grouped.drop(columns=['strong_word_count','weak_word_count'], inplace=True)\n",
    "df_grouped['date'] = pd.to_datetime(df_grouped['date'])\n",
    "df_grouped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('raw_data/NYSE_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f19b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny = pd.read_csv('nyse_processed.csv', index_col=0)\n",
    "ny['Date'] = pd.to_datetime(ny['Date'])\n",
    "ny = ny.rename(columns={'Date':'date'})\n",
    "ny.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_grouped.merge(ny, on='date', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c98795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['negative_score'] = df_merged['negative_word_count']/df_merged['length']\n",
    "df_merged['positive_score'] = df_merged['positive_word_count']/df_merged['length']\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = df_merged.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35009726",
   "metadata": {},
   "source": [
    "# NEW NEW NEW NEW NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "75d56d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20315\\AppData\\Local\\Temp\\ipykernel_17168\\3819209801.py:4: DtypeWarning: Columns (63,108,109,110,176) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dict_df = pd.read_csv('inquirerbasic.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON -- Senate negotiators and the Trump...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athletes around the world breathed a sigh of r...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This month, tens of thousands marched in Spain...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON -- The Environmental Protection Age...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOS ANGELES -- Southern California's always-ja...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       date length\n",
       "0  WASHINGTON -- Senate negotiators and the Trump...  25-Mar-20    639\n",
       "1  Athletes around the world breathed a sigh of r...  25-Mar-20    562\n",
       "2  This month, tens of thousands marched in Spain...  25-Mar-20    790\n",
       "3  WASHINGTON -- The Environmental Protection Age...  25-Mar-20    417\n",
       "4  LOS ANGELES -- Southern California's always-ja...  25-Mar-20    995"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wall = pd.read_csv('raw_data/INFO_corpus/wall_street_journal.csv', encoding='latin-1')\n",
    "tgnyt = pd.read_csv('raw_data/INFO_corpus/tgandnyt.csv', encoding='latin-1')\n",
    "dict_df = pd.read_csv('inquirerbasic.csv')\n",
    "wall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5b2627ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A number of other changes were announced inclu...</td>\n",
       "      <td>5-May-20</td>\n",
       "      <td>633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A small Buffalo manufacturer has had to trim i...</td>\n",
       "      <td>5-May-20</td>\n",
       "      <td>1607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An internal Trump administration model project...</td>\n",
       "      <td>5-May-20</td>\n",
       "      <td>1674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As businesses contemplate the return of worker...</td>\n",
       "      <td>5-May-20</td>\n",
       "      <td>1390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Largely confined to their homes and worried ab...</td>\n",
       "      <td>5-May-20</td>\n",
       "      <td>1507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body      date  length\n",
       "0  A number of other changes were announced inclu...  5-May-20   633.0\n",
       "1  A small Buffalo manufacturer has had to trim i...  5-May-20  1607.0\n",
       "2  An internal Trump administration model project...  5-May-20  1674.0\n",
       "3  As businesses contemplate the return of worker...  5-May-20  1390.0\n",
       "4  Largely confined to their homes and worried ab...  5-May-20  1507.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgnyt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "02dc9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.concat([wall, tgnyt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6658954e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13053 entries, 0 to 6172\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   body    12994 non-null  object\n",
      " 1   date    12875 non-null  object\n",
      " 2   length  12912 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 407.9+ KB\n"
     ]
    }
   ],
   "source": [
    "info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1d1a8a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12849 entries, 0 to 6172\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   body    12849 non-null  object\n",
      " 1   date    12849 non-null  object\n",
      " 2   length  12849 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 401.5+ KB\n"
     ]
    }
   ],
   "source": [
    "info = info.dropna()\n",
    "info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c5e88af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON -- Senate negotiators and the Trump...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athletes around the world breathed a sigh of r...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This month, tens of thousands marched in Spain...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON -- The Environmental Protection Age...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOS ANGELES -- Southern California's always-ja...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       date length\n",
       "0  WASHINGTON -- Senate negotiators and the Trump...  25-Mar-20    639\n",
       "1  Athletes around the world breathed a sigh of r...  25-Mar-20    562\n",
       "2  This month, tens of thousands marched in Spain...  25-Mar-20    790\n",
       "3  WASHINGTON -- The Environmental Protection Age...  25-Mar-20    417\n",
       "4  LOS ANGELES -- Southern California's always-ja...  25-Mar-20    995"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fd63a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = dict_df[dict_df['Positiv'].notnull()]['Entry'].str.lower().tolist()\n",
    "negative_words = dict_df[dict_df['Negativ'].notnull()]['Entry'].str.lower().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1b25acf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\20315\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "def count_positive_words(body):\n",
    "    # Check if body is not a string (it could be nan or a number)\n",
    "    if not isinstance(body, str):\n",
    "        return 0\n",
    "    \n",
    "    # Remove punctuation and convert the body to lowercase\n",
    "    body = body.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the body\n",
    "    tokens = word_tokenize(body)\n",
    "    \n",
    "    # Count the positive words\n",
    "    return sum(token in positive_words for token in tokens)\n",
    "\n",
    "\n",
    "def count_negative_words(body):\n",
    "    # Check if body is not a string (it could be nan or a number)\n",
    "    if not isinstance(body, str):\n",
    "        return 0\n",
    "    \n",
    "    # Remove punctuation and convert the body to lowercase\n",
    "    body = body.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the body\n",
    "    tokens = word_tokenize(body)\n",
    "    \n",
    "    # Count the negative words\n",
    "    return sum(token in negative_words for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f7b99ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "info['positive_word_count'] = info['body'].apply(count_positive_words)\n",
    "# Add a new column 'negative_word_count' to the DataFrame\n",
    "info['negative_word_count'] = info['body'].apply(count_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6876bdda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON -- Senate negotiators and the Trump...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>639</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athletes around the world breathed a sigh of r...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>562</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This month, tens of thousands marched in Spain...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>790</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON -- The Environmental Protection Age...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>417</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOS ANGELES -- Southern California's always-ja...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>995</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       date length  \\\n",
       "0  WASHINGTON -- Senate negotiators and the Trump...  25-Mar-20    639   \n",
       "1  Athletes around the world breathed a sigh of r...  25-Mar-20    562   \n",
       "2  This month, tens of thousands marched in Spain...  25-Mar-20    790   \n",
       "3  WASHINGTON -- The Environmental Protection Age...  25-Mar-20    417   \n",
       "4  LOS ANGELES -- Southern California's always-ja...  25-Mar-20    995   \n",
       "\n",
       "   positive_word_count  negative_word_count  \n",
       "0                   16                    4  \n",
       "1                    6                    5  \n",
       "2                   12                   14  \n",
       "3                   12                    6  \n",
       "4                   13                    3  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "775b2777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      12849\n",
       "unique       396\n",
       "top        2020\"\n",
       "freq        1703\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c3dfb1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON -- Senate negotiators and the Trump...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>639</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athletes around the world breathed a sigh of r...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>562</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This month, tens of thousands marched in Spain...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>790</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON -- The Environmental Protection Age...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>417</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOS ANGELES -- Southern California's always-ja...</td>\n",
       "      <td>25-Mar-20</td>\n",
       "      <td>995</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6161</th>\n",
       "      <td>When Chinese scientists alerted colleagues to ...</td>\n",
       "      <td>12-Dec-20</td>\n",
       "      <td>1772.0</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6163</th>\n",
       "      <td>Theyâre loyal diligent â?and have unbeatabl...</td>\n",
       "      <td>12-Dec-20</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166</th>\n",
       "      <td>Air quality found to be the same or worse than...</td>\n",
       "      <td>11-Dec-20</td>\n",
       "      <td>601.0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>Field hospitals are set up in California Texas...</td>\n",
       "      <td>11-Dec-20</td>\n",
       "      <td>944.0</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>New government loans welcomed by National Thea...</td>\n",
       "      <td>11-Dec-20</td>\n",
       "      <td>617.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11092 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body       date  length  \\\n",
       "0     WASHINGTON -- Senate negotiators and the Trump...  25-Mar-20     639   \n",
       "1     Athletes around the world breathed a sigh of r...  25-Mar-20     562   \n",
       "2     This month, tens of thousands marched in Spain...  25-Mar-20     790   \n",
       "3     WASHINGTON -- The Environmental Protection Age...  25-Mar-20     417   \n",
       "4     LOS ANGELES -- Southern California's always-ja...  25-Mar-20     995   \n",
       "...                                                 ...        ...     ...   \n",
       "6161  When Chinese scientists alerted colleagues to ...  12-Dec-20  1772.0   \n",
       "6163  Theyâre loyal diligent â?and have unbeatabl...  12-Dec-20  1971.0   \n",
       "6166  Air quality found to be the same or worse than...  11-Dec-20   601.0   \n",
       "6171  Field hospitals are set up in California Texas...  11-Dec-20   944.0   \n",
       "6172  New government loans welcomed by National Thea...  11-Dec-20   617.0   \n",
       "\n",
       "      positive_word_count  negative_word_count  \n",
       "0                      16                    4  \n",
       "1                       6                    5  \n",
       "2                      12                   14  \n",
       "3                      12                    6  \n",
       "4                      13                    3  \n",
       "...                   ...                  ...  \n",
       "6161                   34                   22  \n",
       "6163                   34                   21  \n",
       "6166                    9                   14  \n",
       "6171                   21                   15  \n",
       "6172                   16                    4  \n",
       "\n",
       "[11092 rows x 5 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info1 = info\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def is_date(string):\n",
    "    try: \n",
    "        parse(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Convert all dates to strings before trying to parse them\n",
    "info1['date'] = info1['date'].astype(str)\n",
    "\n",
    "# Create a boolean mask for the rows with good dates\n",
    "mask = info1['date'].apply(is_date)\n",
    "\n",
    "# Keep only the rows with good dates (and drop the rows with bad dates)\n",
    "info1 = info1[mask]\n",
    "info1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "13e7c751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20315\\AppData\\Local\\Temp\\ipykernel_17168\\3360093039.py:5: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  return pd.datetime.strptime(date, fmt)\n",
      "C:\\Users\\20315\\AppData\\Local\\Temp\\ipykernel_17168\\3360093039.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info1['date'] = info1['date'].apply(parse_dates)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON -- Senate negotiators and the Trump...</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>639</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athletes around the world breathed a sigh of r...</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>562</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This month, tens of thousands marched in Spain...</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>790</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON -- The Environmental Protection Age...</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>417</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOS ANGELES -- Southern California's always-ja...</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>995</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       date length  \\\n",
       "0  WASHINGTON -- Senate negotiators and the Trump... 2020-03-25    639   \n",
       "1  Athletes around the world breathed a sigh of r... 2020-03-25    562   \n",
       "2  This month, tens of thousands marched in Spain... 2020-03-25    790   \n",
       "3  WASHINGTON -- The Environmental Protection Age... 2020-03-25    417   \n",
       "4  LOS ANGELES -- Southern California's always-ja... 2020-03-25    995   \n",
       "\n",
       "   positive_word_count  negative_word_count  \n",
       "0                   16                    4  \n",
       "1                    6                    5  \n",
       "2                   12                   14  \n",
       "3                   12                    6  \n",
       "4                   13                    3  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function to handle multiple date formats\n",
    "def parse_dates(date):\n",
    "    for fmt in ('%b%d,%Y', '%d-%b-%y'):\n",
    "        try:\n",
    "            return pd.datetime.strptime(date, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return np.nan\n",
    "\n",
    "# Apply the function to the date column\n",
    "info1['date'] = info1['date'].apply(parse_dates)\n",
    "\n",
    "\n",
    "info1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "59c5e8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11092 entries, 0 to 6172\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   body                 11092 non-null  object        \n",
      " 1   date                 11083 non-null  datetime64[ns]\n",
      " 2   length               11092 non-null  object        \n",
      " 3   positive_word_count  11092 non-null  int64         \n",
      " 4   negative_word_count  11092 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 519.9+ KB\n"
     ]
    }
   ],
   "source": [
    "info1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3fa1ee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   body date length  \\\n",
      "1249  WASHINGTON -- U.S. production of crude oil wil...  NaT    369   \n",
      "2886  Four years ago, Aaron Levie moved Box Inc., th...  NaT    921   \n",
      "3204  With the sports world reeling from the coronav...  NaT   1063   \n",
      "3759  Coronavirus cases surged in the U.S., outstrip...  NaT   1056   \n",
      "5578  MITSUBISHI CHEMICAL\\nForeign Executive\\nAppoin...  NaT    805   \n",
      "6017  The U.S. Centers for Disease Control and Preve...  NaT    604   \n",
      "6769  NEW DELHI -- The companies behind two of the m...  NaT    389   \n",
      "2935  Residents locked up in allegedly âinhumanâ?...  NaT  900.0   \n",
      "4925  Attendance rates at their lowest in highCovid ...  NaT  537.0   \n",
      "\n",
      "      positive_word_count  negative_word_count  \n",
      "1249                    5                    6  \n",
      "2886                   22                    3  \n",
      "3204                   28                   15  \n",
      "3759                   12                   11  \n",
      "5578                    4                    3  \n",
      "6017                    9                    9  \n",
      "6769                    4                    3  \n",
      "2935                   18                   14  \n",
      "4925                   13                    4  \n"
     ]
    }
   ],
   "source": [
    "# Show rows where 'date' or 'length' is null\n",
    "missing_dates_or_lengths = info1[info1['date'].isnull() | info1['length'].isnull()]\n",
    "print(missing_dates_or_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d78cb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11083 entries, 0 to 6172\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   body                 11083 non-null  object        \n",
      " 1   date                 11083 non-null  datetime64[ns]\n",
      " 2   length               11083 non-null  object        \n",
      " 3   positive_word_count  11083 non-null  int64         \n",
      " 4   negative_word_count  11083 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 519.5+ KB\n"
     ]
    }
   ],
   "source": [
    "info1 = info1.dropna(subset=['date', 'length'])\n",
    "info1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "753e4c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The deadly coronavirus outbreak is sparking bi...</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>386</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BEIJING -- It didn't take long to identify the...</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>1599</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BEIJING -- The mayor of Wuhan, the city at the...</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1094</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investors who began the year feeling largely s...</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>675</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Commodities including crude oil and copper fel...</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       date length  \\\n",
       "0  The deadly coronavirus outbreak is sparking bi... 2020-01-23    386   \n",
       "1  BEIJING -- It didn't take long to identify the... 2020-01-27   1599   \n",
       "2  BEIJING -- The mayor of Wuhan, the city at the... 2020-01-28   1094   \n",
       "3  Investors who began the year feeling largely s... 2020-01-29    675   \n",
       "4  Commodities including crude oil and copper fel... 2020-01-31    530   \n",
       "\n",
       "   positive_word_count  negative_word_count  \n",
       "0                    5                   10  \n",
       "1                   23                   32  \n",
       "2                   30                   25  \n",
       "3                    7                   18  \n",
       "4                    0                   14  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by date in ascending order\n",
    "info1 = info1.sort_values(by='date')\n",
    "info1 = info1.reset_index(drop=True)\n",
    "# Check the result\n",
    "info1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a07d605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>386</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>1599</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1094</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>675</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date length  positive_word_count  negative_word_count\n",
       "0 2020-01-23    386                    5                   10\n",
       "1 2020-01-27   1599                   23                   32\n",
       "2 2020-01-28   1094                   30                   25\n",
       "3 2020-01-29    675                    7                   18\n",
       "4 2020-01-31    530                    0                   14"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['body']\n",
    "info1.drop(columns=columns_to_drop, inplace=True)\n",
    "info1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "85ba269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11083 entries, 0 to 11082\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   date                 11083 non-null  datetime64[ns]\n",
      " 1   length               11083 non-null  object        \n",
      " 2   positive_word_count  11083 non-null  int64         \n",
      " 3   negative_word_count  11083 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(1)\n",
      "memory usage: 346.5+ KB\n"
     ]
    }
   ],
   "source": [
    "info1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "97858196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11083 entries, 0 to 11082\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   date                 11083 non-null  datetime64[ns]\n",
      " 1   length               11083 non-null  int32         \n",
      " 2   positive_word_count  11083 non-null  int64         \n",
      " 3   negative_word_count  11083 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int32(1), int64(2)\n",
      "memory usage: 303.2 KB\n"
     ]
    }
   ],
   "source": [
    "info1['length'] = info1['length'].astype(int)\n",
    "info1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4e49135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这一步有问题\n",
    "clean_grouped = info1.groupby('date').agg({\n",
    "    'length': 'sum',\n",
    "\n",
    "}).reset_index()\n",
    "clean_grouped.head()\n",
    "clean_grouped.to_csv('cleaned_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "adec0f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333 entries, 0 to 332\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   date                 333 non-null    datetime64[ns]\n",
      " 1   length               333 non-null    int32         \n",
      " 2   positive_word_count  333 non-null    int64         \n",
      " 3   negative_word_count  333 non-null    int64         \n",
      "dtypes: datetime64[ns](1), int32(1), int64(2)\n",
      "memory usage: 9.2 KB\n"
     ]
    }
   ],
   "source": [
    "clean_grouped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f5f0ad90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 333 entries, 0 to 332\n",
      "Series name: date\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "333 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 2.7 KB\n"
     ]
    }
   ],
   "source": [
    "clean_grouped['date'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f2e70ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 777 entries, 0 to 776\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   date            777 non-null    datetime64[ns]\n",
      " 1   Open            777 non-null    float64       \n",
      " 2   High            777 non-null    float64       \n",
      " 3   Low             777 non-null    float64       \n",
      " 4   Close           777 non-null    float64       \n",
      " 5   Adj Close       777 non-null    float64       \n",
      " 6   Volume          777 non-null    int64         \n",
      " 7   Daily_return    776 non-null    float64       \n",
      " 8   Trend           777 non-null    object        \n",
      " 9   Trend_duration  777 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(6), int64(2), object(1)\n",
      "memory usage: 66.8+ KB\n"
     ]
    }
   ],
   "source": [
    "ny = pd.read_csv('nyse_processed.csv', index_col=0)\n",
    "ny['Date'] = pd.to_datetime(ny['Date'])\n",
    "ny = ny.rename(columns={'Date':'date'})\n",
    "ny.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fd30e9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_return</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Trend_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>386</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>14064.280273</td>\n",
       "      <td>14109.589844</td>\n",
       "      <td>14003.280273</td>\n",
       "      <td>14102.040039</td>\n",
       "      <td>14102.040039</td>\n",
       "      <td>3766710000</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>1599</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>13746.629883</td>\n",
       "      <td>13826.429688</td>\n",
       "      <td>13742.009766</td>\n",
       "      <td>13769.599609</td>\n",
       "      <td>13769.599609</td>\n",
       "      <td>3831050000</td>\n",
       "      <td>-0.014942</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1094</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>13812.650391</td>\n",
       "      <td>13913.589844</td>\n",
       "      <td>13798.339844</td>\n",
       "      <td>13877.610352</td>\n",
       "      <td>13877.610352</td>\n",
       "      <td>3531570000</td>\n",
       "      <td>0.007844</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>675</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>13912.790039</td>\n",
       "      <td>13922.440430</td>\n",
       "      <td>13843.790039</td>\n",
       "      <td>13843.809570</td>\n",
       "      <td>13843.809570</td>\n",
       "      <td>3600250000</td>\n",
       "      <td>-0.002436</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13783.809570</td>\n",
       "      <td>13788.219727</td>\n",
       "      <td>13573.040039</td>\n",
       "      <td>13614.099609</td>\n",
       "      <td>13614.099609</td>\n",
       "      <td>4529700000</td>\n",
       "      <td>-0.017878</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>814</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>13964.000000</td>\n",
       "      <td>14029.910156</td>\n",
       "      <td>13947.589844</td>\n",
       "      <td>14024.860352</td>\n",
       "      <td>14024.860352</td>\n",
       "      <td>4121480000</td>\n",
       "      <td>0.011687</td>\n",
       "      <td>UP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>2160</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>14066.900391</td>\n",
       "      <td>14069.330078</td>\n",
       "      <td>14023.480469</td>\n",
       "      <td>14034.950195</td>\n",
       "      <td>14034.950195</td>\n",
       "      <td>3887250000</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>UP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13987.509766</td>\n",
       "      <td>13987.509766</td>\n",
       "      <td>13912.040039</td>\n",
       "      <td>13931.929688</td>\n",
       "      <td>13931.929688</td>\n",
       "      <td>3733920000</td>\n",
       "      <td>-0.007340</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>2963</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>14117.830078</td>\n",
       "      <td>14148.240234</td>\n",
       "      <td>14108.519531</td>\n",
       "      <td>14136.980469</td>\n",
       "      <td>14136.980469</td>\n",
       "      <td>3930910000</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>UP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>4127</td>\n",
       "      <td>48</td>\n",
       "      <td>59</td>\n",
       "      <td>14069.250000</td>\n",
       "      <td>14132.879883</td>\n",
       "      <td>14049.129883</td>\n",
       "      <td>14099.040039</td>\n",
       "      <td>14099.040039</td>\n",
       "      <td>3500890000</td>\n",
       "      <td>-0.002684</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>3602</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>14104.769531</td>\n",
       "      <td>14110.190430</td>\n",
       "      <td>14046.599609</td>\n",
       "      <td>14097.339844</td>\n",
       "      <td>14097.339844</td>\n",
       "      <td>3419700000</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>2628</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>14047.910156</td>\n",
       "      <td>14072.690430</td>\n",
       "      <td>13990.700195</td>\n",
       "      <td>14039.009766</td>\n",
       "      <td>14039.009766</td>\n",
       "      <td>3750400000</td>\n",
       "      <td>-0.004138</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>803</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>14077.509766</td>\n",
       "      <td>14115.950195</td>\n",
       "      <td>14066.240234</td>\n",
       "      <td>14087.129883</td>\n",
       "      <td>14087.129883</td>\n",
       "      <td>3614200000</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>2759</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>14061.040039</td>\n",
       "      <td>14104.919922</td>\n",
       "      <td>13955.750000</td>\n",
       "      <td>14061.480469</td>\n",
       "      <td>14061.480469</td>\n",
       "      <td>4019180000</td>\n",
       "      <td>-0.001821</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>1538</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>14014.629883</td>\n",
       "      <td>14014.629883</td>\n",
       "      <td>13931.129883</td>\n",
       "      <td>13975.780273</td>\n",
       "      <td>13975.780273</td>\n",
       "      <td>3908780000</td>\n",
       "      <td>-0.006095</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5284</td>\n",
       "      <td>60</td>\n",
       "      <td>87</td>\n",
       "      <td>13654.000000</td>\n",
       "      <td>13654.000000</td>\n",
       "      <td>13493.679688</td>\n",
       "      <td>13534.120117</td>\n",
       "      <td>13534.120117</td>\n",
       "      <td>4851160000</td>\n",
       "      <td>-0.031602</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>2884</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>13570.209961</td>\n",
       "      <td>13582.740234</td>\n",
       "      <td>13110.089844</td>\n",
       "      <td>13143.730469</td>\n",
       "      <td>13143.730469</td>\n",
       "      <td>5596760000</td>\n",
       "      <td>-0.028845</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>3417</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>13194.309570</td>\n",
       "      <td>13323.339844</td>\n",
       "      <td>13041.940430</td>\n",
       "      <td>13046.620117</td>\n",
       "      <td>13046.620117</td>\n",
       "      <td>5484650000</td>\n",
       "      <td>-0.007388</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>8222</td>\n",
       "      <td>105</td>\n",
       "      <td>165</td>\n",
       "      <td>12841.400391</td>\n",
       "      <td>12977.179688</td>\n",
       "      <td>12544.990234</td>\n",
       "      <td>12547.250000</td>\n",
       "      <td>12547.250000</td>\n",
       "      <td>7064710000</td>\n",
       "      <td>-0.038276</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>10475</td>\n",
       "      <td>131</td>\n",
       "      <td>202</td>\n",
       "      <td>12547.250000</td>\n",
       "      <td>12547.250000</td>\n",
       "      <td>12024.450195</td>\n",
       "      <td>12380.969727</td>\n",
       "      <td>12380.969727</td>\n",
       "      <td>8569570000</td>\n",
       "      <td>-0.013252</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>6786</td>\n",
       "      <td>115</td>\n",
       "      <td>106</td>\n",
       "      <td>12441.429688</td>\n",
       "      <td>12830.129883</td>\n",
       "      <td>12316.179688</td>\n",
       "      <td>12827.990234</td>\n",
       "      <td>12827.990234</td>\n",
       "      <td>6381330000</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>8417</td>\n",
       "      <td>161</td>\n",
       "      <td>149</td>\n",
       "      <td>12845.059570</td>\n",
       "      <td>13015.660156</td>\n",
       "      <td>12432.519531</td>\n",
       "      <td>12542.740234</td>\n",
       "      <td>12542.740234</td>\n",
       "      <td>6376510000</td>\n",
       "      <td>-0.022237</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>16231</td>\n",
       "      <td>271</td>\n",
       "      <td>298</td>\n",
       "      <td>12696.610352</td>\n",
       "      <td>13011.450195</td>\n",
       "      <td>12673.900391</td>\n",
       "      <td>13009.959961</td>\n",
       "      <td>13009.959961</td>\n",
       "      <td>5073020000</td>\n",
       "      <td>0.037250</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>10742</td>\n",
       "      <td>167</td>\n",
       "      <td>184</td>\n",
       "      <td>12740.860352</td>\n",
       "      <td>12786.639648</td>\n",
       "      <td>12489.769531</td>\n",
       "      <td>12593.030273</td>\n",
       "      <td>12593.030273</td>\n",
       "      <td>5579290000</td>\n",
       "      <td>-0.032047</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>6239</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>12593.030273</td>\n",
       "      <td>12593.030273</td>\n",
       "      <td>12106.740234</td>\n",
       "      <td>12352.030273</td>\n",
       "      <td>12352.030273</td>\n",
       "      <td>6555240000</td>\n",
       "      <td>-0.019138</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>5066</td>\n",
       "      <td>104</td>\n",
       "      <td>80</td>\n",
       "      <td>11748.610352</td>\n",
       "      <td>11748.610352</td>\n",
       "      <td>11240.769531</td>\n",
       "      <td>11298.429688</td>\n",
       "      <td>11298.429688</td>\n",
       "      <td>8441290000</td>\n",
       "      <td>-0.085298</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>7066</td>\n",
       "      <td>129</td>\n",
       "      <td>116</td>\n",
       "      <td>11635.219727</td>\n",
       "      <td>11794.009766</td>\n",
       "      <td>11246.519531</td>\n",
       "      <td>11793.269531</td>\n",
       "      <td>11793.269531</td>\n",
       "      <td>7642040000</td>\n",
       "      <td>0.043797</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>14711</td>\n",
       "      <td>235</td>\n",
       "      <td>224</td>\n",
       "      <td>11523.940430</td>\n",
       "      <td>11523.940430</td>\n",
       "      <td>11053.790039</td>\n",
       "      <td>11177.290039</td>\n",
       "      <td>11177.290039</td>\n",
       "      <td>7431200000</td>\n",
       "      <td>-0.052231</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>12066</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>10466.700195</td>\n",
       "      <td>10646.919922</td>\n",
       "      <td>10054.469727</td>\n",
       "      <td>10060.759766</td>\n",
       "      <td>10060.759766</td>\n",
       "      <td>8850810000</td>\n",
       "      <td>-0.099893</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>31733</td>\n",
       "      <td>562</td>\n",
       "      <td>489</td>\n",
       "      <td>10445.440430</td>\n",
       "      <td>10851.750000</td>\n",
       "      <td>10060.349609</td>\n",
       "      <td>10851.740234</td>\n",
       "      <td>10851.740234</td>\n",
       "      <td>8299070000</td>\n",
       "      <td>0.078620</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>49026</td>\n",
       "      <td>779</td>\n",
       "      <td>641</td>\n",
       "      <td>10851.980469</td>\n",
       "      <td>10851.980469</td>\n",
       "      <td>9559.230469</td>\n",
       "      <td>9567.530273</td>\n",
       "      <td>9567.530273</td>\n",
       "      <td>7805450000</td>\n",
       "      <td>-0.118341</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>48700</td>\n",
       "      <td>783</td>\n",
       "      <td>681</td>\n",
       "      <td>9726.179688</td>\n",
       "      <td>10154.160156</td>\n",
       "      <td>9484.650391</td>\n",
       "      <td>10063.360352</td>\n",
       "      <td>10063.360352</td>\n",
       "      <td>8370250000</td>\n",
       "      <td>0.051824</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>62204</td>\n",
       "      <td>1004</td>\n",
       "      <td>943</td>\n",
       "      <td>9562.490234</td>\n",
       "      <td>9666.570313</td>\n",
       "      <td>8953.599609</td>\n",
       "      <td>9384.599609</td>\n",
       "      <td>9384.599609</td>\n",
       "      <td>8799300000</td>\n",
       "      <td>-0.067449</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>55740</td>\n",
       "      <td>808</td>\n",
       "      <td>798</td>\n",
       "      <td>9313.759766</td>\n",
       "      <td>9622.209961</td>\n",
       "      <td>9048.360352</td>\n",
       "      <td>9461.309570</td>\n",
       "      <td>9461.309570</td>\n",
       "      <td>7956100000</td>\n",
       "      <td>0.008174</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>38467</td>\n",
       "      <td>564</td>\n",
       "      <td>450</td>\n",
       "      <td>9577.900391</td>\n",
       "      <td>9676.940430</td>\n",
       "      <td>9108.150391</td>\n",
       "      <td>9133.160156</td>\n",
       "      <td>9133.160156</td>\n",
       "      <td>9053950000</td>\n",
       "      <td>-0.034683</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>53178</td>\n",
       "      <td>882</td>\n",
       "      <td>718</td>\n",
       "      <td>9014.580078</td>\n",
       "      <td>9053.490234</td>\n",
       "      <td>8664.940430</td>\n",
       "      <td>8777.379883</td>\n",
       "      <td>8777.379883</td>\n",
       "      <td>7411380000</td>\n",
       "      <td>-0.038955</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>50573</td>\n",
       "      <td>745</td>\n",
       "      <td>632</td>\n",
       "      <td>9276.639648</td>\n",
       "      <td>9672.009766</td>\n",
       "      <td>9276.639648</td>\n",
       "      <td>9658.320313</td>\n",
       "      <td>9658.320313</td>\n",
       "      <td>7563150000</td>\n",
       "      <td>0.100365</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>39823</td>\n",
       "      <td>618</td>\n",
       "      <td>442</td>\n",
       "      <td>9749.799805</td>\n",
       "      <td>10303.900391</td>\n",
       "      <td>9591.740234</td>\n",
       "      <td>9961.379883</td>\n",
       "      <td>9961.379883</td>\n",
       "      <td>8300010000</td>\n",
       "      <td>0.031378</td>\n",
       "      <td>UP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>64246</td>\n",
       "      <td>1095</td>\n",
       "      <td>917</td>\n",
       "      <td>10060.480469</td>\n",
       "      <td>10556.900391</td>\n",
       "      <td>10060.480469</td>\n",
       "      <td>10536.280273</td>\n",
       "      <td>10536.280273</td>\n",
       "      <td>7766990000</td>\n",
       "      <td>0.057713</td>\n",
       "      <td>UP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>69381</td>\n",
       "      <td>1101</td>\n",
       "      <td>942</td>\n",
       "      <td>10135.730469</td>\n",
       "      <td>10449.219727</td>\n",
       "      <td>10064.500000</td>\n",
       "      <td>10187.209961</td>\n",
       "      <td>10187.209961</td>\n",
       "      <td>6201670000</td>\n",
       "      <td>-0.033130</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>56018</td>\n",
       "      <td>896</td>\n",
       "      <td>799</td>\n",
       "      <td>10238.129883</td>\n",
       "      <td>10455.769531</td>\n",
       "      <td>10131.599609</td>\n",
       "      <td>10434.740234</td>\n",
       "      <td>10434.740234</td>\n",
       "      <td>5751120000</td>\n",
       "      <td>0.024298</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>60170</td>\n",
       "      <td>986</td>\n",
       "      <td>769</td>\n",
       "      <td>10387.730469</td>\n",
       "      <td>10499.799805</td>\n",
       "      <td>10237.219727</td>\n",
       "      <td>10301.870117</td>\n",
       "      <td>10301.870117</td>\n",
       "      <td>6576210000</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>67172</td>\n",
       "      <td>1083</td>\n",
       "      <td>791</td>\n",
       "      <td>9917.309570</td>\n",
       "      <td>10029.000000</td>\n",
       "      <td>9766.799805</td>\n",
       "      <td>9844.849609</td>\n",
       "      <td>9844.849609</td>\n",
       "      <td>5964000000</td>\n",
       "      <td>-0.044363</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>63209</td>\n",
       "      <td>1063</td>\n",
       "      <td>851</td>\n",
       "      <td>9815.269531</td>\n",
       "      <td>10142.009766</td>\n",
       "      <td>9813.509766</td>\n",
       "      <td>10062.370117</td>\n",
       "      <td>10062.370117</td>\n",
       "      <td>6464190000</td>\n",
       "      <td>0.022095</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>36073</td>\n",
       "      <td>599</td>\n",
       "      <td>476</td>\n",
       "      <td>10012.469727</td>\n",
       "      <td>10075.910156</td>\n",
       "      <td>9774.240234</td>\n",
       "      <td>9880.629883</td>\n",
       "      <td>9880.629883</td>\n",
       "      <td>6096970000</td>\n",
       "      <td>-0.018061</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>61801</td>\n",
       "      <td>1060</td>\n",
       "      <td>853</td>\n",
       "      <td>10264.129883</td>\n",
       "      <td>10560.730469</td>\n",
       "      <td>10233.040039</td>\n",
       "      <td>10515.240234</td>\n",
       "      <td>10515.240234</td>\n",
       "      <td>6403840000</td>\n",
       "      <td>0.064228</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>62726</td>\n",
       "      <td>1069</td>\n",
       "      <td>819</td>\n",
       "      <td>10894.200195</td>\n",
       "      <td>10912.559570</td>\n",
       "      <td>10534.740234</td>\n",
       "      <td>10537.040039</td>\n",
       "      <td>10537.040039</td>\n",
       "      <td>7050410000</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>UP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>62078</td>\n",
       "      <td>963</td>\n",
       "      <td>849</td>\n",
       "      <td>10641.509766</td>\n",
       "      <td>10939.969727</td>\n",
       "      <td>10538.650391</td>\n",
       "      <td>10902.589844</td>\n",
       "      <td>10902.589844</td>\n",
       "      <td>5875710000</td>\n",
       "      <td>0.034692</td>\n",
       "      <td>UP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>67447</td>\n",
       "      <td>1074</td>\n",
       "      <td>847</td>\n",
       "      <td>11070.320313</td>\n",
       "      <td>11272.480469</td>\n",
       "      <td>11019.820313</td>\n",
       "      <td>11136.610352</td>\n",
       "      <td>11136.610352</td>\n",
       "      <td>7899550000</td>\n",
       "      <td>0.021465</td>\n",
       "      <td>UP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>62980</td>\n",
       "      <td>981</td>\n",
       "      <td>882</td>\n",
       "      <td>11136.610352</td>\n",
       "      <td>11136.610352</td>\n",
       "      <td>10817.150391</td>\n",
       "      <td>10949.530273</td>\n",
       "      <td>10949.530273</td>\n",
       "      <td>5319530000</td>\n",
       "      <td>-0.016799</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  length  positive_word_count  negative_word_count          Open  \\\n",
       "0  2020-01-23     386                    5                   10  14064.280273   \n",
       "1  2020-01-27    1599                   23                   32  13746.629883   \n",
       "2  2020-01-28    1094                   30                   25  13812.650391   \n",
       "3  2020-01-29     675                    7                   18  13912.790039   \n",
       "4  2020-01-31     530                    0                   14  13783.809570   \n",
       "5  2020-02-05     814                   10                   12  13964.000000   \n",
       "6  2020-02-06    2160                   10                   37  14066.900391   \n",
       "7  2020-02-07     259                    0                    3  13987.509766   \n",
       "8  2020-02-12    2963                   45                   39  14117.830078   \n",
       "9  2020-02-13    4127                   48                   59  14069.250000   \n",
       "10 2020-02-14    3602                   76                   50  14104.769531   \n",
       "11 2020-02-18    2628                   33                   41  14047.910156   \n",
       "12 2020-02-19     803                    3                   10  14077.509766   \n",
       "13 2020-02-20    2759                   46                   47  14061.040039   \n",
       "14 2020-02-21    1538                   35                   32  14014.629883   \n",
       "15 2020-02-24    5284                   60                   87  13654.000000   \n",
       "16 2020-02-25    2884                   63                   44  13570.209961   \n",
       "17 2020-02-26    3417                   53                   45  13194.309570   \n",
       "18 2020-02-27    8222                  105                  165  12841.400391   \n",
       "19 2020-02-28   10475                  131                  202  12547.250000   \n",
       "20 2020-03-02    6786                  115                  106  12441.429688   \n",
       "21 2020-03-03    8417                  161                  149  12845.059570   \n",
       "22 2020-03-04   16231                  271                  298  12696.610352   \n",
       "23 2020-03-05   10742                  167                  184  12740.860352   \n",
       "24 2020-03-06    6239                   93                   82  12593.030273   \n",
       "25 2020-03-09    5066                  104                   80  11748.610352   \n",
       "26 2020-03-10    7066                  129                  116  11635.219727   \n",
       "27 2020-03-11   14711                  235                  224  11523.940430   \n",
       "28 2020-03-12   12066                  180                  184  10466.700195   \n",
       "29 2020-03-13   31733                  562                  489  10445.440430   \n",
       "30 2020-03-16   49026                  779                  641  10851.980469   \n",
       "31 2020-03-17   48700                  783                  681   9726.179688   \n",
       "32 2020-03-18   62204                 1004                  943   9562.490234   \n",
       "33 2020-03-19   55740                  808                  798   9313.759766   \n",
       "34 2020-03-20   38467                  564                  450   9577.900391   \n",
       "35 2020-03-23   53178                  882                  718   9014.580078   \n",
       "36 2020-03-24   50573                  745                  632   9276.639648   \n",
       "37 2020-03-25   39823                  618                  442   9749.799805   \n",
       "38 2020-03-26   64246                 1095                  917  10060.480469   \n",
       "39 2020-03-27   69381                 1101                  942  10135.730469   \n",
       "40 2020-03-30   56018                  896                  799  10238.129883   \n",
       "41 2020-03-31   60170                  986                  769  10387.730469   \n",
       "42 2020-04-01   67172                 1083                  791   9917.309570   \n",
       "43 2020-04-02   63209                 1063                  851   9815.269531   \n",
       "44 2020-04-03   36073                  599                  476  10012.469727   \n",
       "45 2020-04-06   61801                 1060                  853  10264.129883   \n",
       "46 2020-04-07   62726                 1069                  819  10894.200195   \n",
       "47 2020-04-08   62078                  963                  849  10641.509766   \n",
       "48 2020-04-09   67447                 1074                  847  11070.320313   \n",
       "49 2020-04-13   62980                  981                  882  11136.610352   \n",
       "\n",
       "            High           Low         Close     Adj Close      Volume  \\\n",
       "0   14109.589844  14003.280273  14102.040039  14102.040039  3766710000   \n",
       "1   13826.429688  13742.009766  13769.599609  13769.599609  3831050000   \n",
       "2   13913.589844  13798.339844  13877.610352  13877.610352  3531570000   \n",
       "3   13922.440430  13843.790039  13843.809570  13843.809570  3600250000   \n",
       "4   13788.219727  13573.040039  13614.099609  13614.099609  4529700000   \n",
       "5   14029.910156  13947.589844  14024.860352  14024.860352  4121480000   \n",
       "6   14069.330078  14023.480469  14034.950195  14034.950195  3887250000   \n",
       "7   13987.509766  13912.040039  13931.929688  13931.929688  3733920000   \n",
       "8   14148.240234  14108.519531  14136.980469  14136.980469  3930910000   \n",
       "9   14132.879883  14049.129883  14099.040039  14099.040039  3500890000   \n",
       "10  14110.190430  14046.599609  14097.339844  14097.339844  3419700000   \n",
       "11  14072.690430  13990.700195  14039.009766  14039.009766  3750400000   \n",
       "12  14115.950195  14066.240234  14087.129883  14087.129883  3614200000   \n",
       "13  14104.919922  13955.750000  14061.480469  14061.480469  4019180000   \n",
       "14  14014.629883  13931.129883  13975.780273  13975.780273  3908780000   \n",
       "15  13654.000000  13493.679688  13534.120117  13534.120117  4851160000   \n",
       "16  13582.740234  13110.089844  13143.730469  13143.730469  5596760000   \n",
       "17  13323.339844  13041.940430  13046.620117  13046.620117  5484650000   \n",
       "18  12977.179688  12544.990234  12547.250000  12547.250000  7064710000   \n",
       "19  12547.250000  12024.450195  12380.969727  12380.969727  8569570000   \n",
       "20  12830.129883  12316.179688  12827.990234  12827.990234  6381330000   \n",
       "21  13015.660156  12432.519531  12542.740234  12542.740234  6376510000   \n",
       "22  13011.450195  12673.900391  13009.959961  13009.959961  5073020000   \n",
       "23  12786.639648  12489.769531  12593.030273  12593.030273  5579290000   \n",
       "24  12593.030273  12106.740234  12352.030273  12352.030273  6555240000   \n",
       "25  11748.610352  11240.769531  11298.429688  11298.429688  8441290000   \n",
       "26  11794.009766  11246.519531  11793.269531  11793.269531  7642040000   \n",
       "27  11523.940430  11053.790039  11177.290039  11177.290039  7431200000   \n",
       "28  10646.919922  10054.469727  10060.759766  10060.759766  8850810000   \n",
       "29  10851.750000  10060.349609  10851.740234  10851.740234  8299070000   \n",
       "30  10851.980469   9559.230469   9567.530273   9567.530273  7805450000   \n",
       "31  10154.160156   9484.650391  10063.360352  10063.360352  8370250000   \n",
       "32   9666.570313   8953.599609   9384.599609   9384.599609  8799300000   \n",
       "33   9622.209961   9048.360352   9461.309570   9461.309570  7956100000   \n",
       "34   9676.940430   9108.150391   9133.160156   9133.160156  9053950000   \n",
       "35   9053.490234   8664.940430   8777.379883   8777.379883  7411380000   \n",
       "36   9672.009766   9276.639648   9658.320313   9658.320313  7563150000   \n",
       "37  10303.900391   9591.740234   9961.379883   9961.379883  8300010000   \n",
       "38  10556.900391  10060.480469  10536.280273  10536.280273  7766990000   \n",
       "39  10449.219727  10064.500000  10187.209961  10187.209961  6201670000   \n",
       "40  10455.769531  10131.599609  10434.740234  10434.740234  5751120000   \n",
       "41  10499.799805  10237.219727  10301.870117  10301.870117  6576210000   \n",
       "42  10029.000000   9766.799805   9844.849609   9844.849609  5964000000   \n",
       "43  10142.009766   9813.509766  10062.370117  10062.370117  6464190000   \n",
       "44  10075.910156   9774.240234   9880.629883   9880.629883  6096970000   \n",
       "45  10560.730469  10233.040039  10515.240234  10515.240234  6403840000   \n",
       "46  10912.559570  10534.740234  10537.040039  10537.040039  7050410000   \n",
       "47  10939.969727  10538.650391  10902.589844  10902.589844  5875710000   \n",
       "48  11272.480469  11019.820313  11136.610352  11136.610352  7899550000   \n",
       "49  11136.610352  10817.150391  10949.530273  10949.530273  5319530000   \n",
       "\n",
       "    Daily_return Trend  Trend_duration  \n",
       "0      -0.000581  DOWN               1  \n",
       "1      -0.014942  DOWN               3  \n",
       "2       0.007844    UP               1  \n",
       "3      -0.002436  DOWN               1  \n",
       "4      -0.017878  DOWN               1  \n",
       "5       0.011687    UP               3  \n",
       "6       0.000719    UP               4  \n",
       "7      -0.007340  DOWN               1  \n",
       "8       0.005899    UP               3  \n",
       "9      -0.002684  DOWN               1  \n",
       "10     -0.000121  DOWN               2  \n",
       "11     -0.004138  DOWN               3  \n",
       "12      0.003428    UP               1  \n",
       "13     -0.001821  DOWN               1  \n",
       "14     -0.006095  DOWN               2  \n",
       "15     -0.031602  DOWN               3  \n",
       "16     -0.028845  DOWN               4  \n",
       "17     -0.007388  DOWN               5  \n",
       "18     -0.038276  DOWN               6  \n",
       "19     -0.013252  DOWN               7  \n",
       "20      0.036105    UP               1  \n",
       "21     -0.022237  DOWN               1  \n",
       "22      0.037250    UP               1  \n",
       "23     -0.032047  DOWN               1  \n",
       "24     -0.019138  DOWN               2  \n",
       "25     -0.085298  DOWN               3  \n",
       "26      0.043797    UP               1  \n",
       "27     -0.052231  DOWN               1  \n",
       "28     -0.099893  DOWN               2  \n",
       "29      0.078620    UP               1  \n",
       "30     -0.118341  DOWN               1  \n",
       "31      0.051824    UP               1  \n",
       "32     -0.067449  DOWN               1  \n",
       "33      0.008174    UP               1  \n",
       "34     -0.034683  DOWN               1  \n",
       "35     -0.038955  DOWN               2  \n",
       "36      0.100365    UP               1  \n",
       "37      0.031378    UP               2  \n",
       "38      0.057713    UP               3  \n",
       "39     -0.033130  DOWN               1  \n",
       "40      0.024298    UP               1  \n",
       "41     -0.012733  DOWN               1  \n",
       "42     -0.044363  DOWN               2  \n",
       "43      0.022095    UP               1  \n",
       "44     -0.018061  DOWN               1  \n",
       "45      0.064228    UP               1  \n",
       "46      0.002073    UP               2  \n",
       "47      0.034692    UP               3  \n",
       "48      0.021465    UP               4  \n",
       "49     -0.016799  DOWN               1  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_merged = clean_grouped.merge(ny, on='date', how='inner')\n",
    "clean_merged.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5541b913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_return</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Trend_duration</th>\n",
       "      <th>negative_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>386</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>14064.280273</td>\n",
       "      <td>14109.589844</td>\n",
       "      <td>14003.280273</td>\n",
       "      <td>14102.040039</td>\n",
       "      <td>14102.040039</td>\n",
       "      <td>3766710000</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>1599</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>13746.629883</td>\n",
       "      <td>13826.429688</td>\n",
       "      <td>13742.009766</td>\n",
       "      <td>13769.599609</td>\n",
       "      <td>13769.599609</td>\n",
       "      <td>3831050000</td>\n",
       "      <td>-0.014942</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.020013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1094</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>13812.650391</td>\n",
       "      <td>13913.589844</td>\n",
       "      <td>13798.339844</td>\n",
       "      <td>13877.610352</td>\n",
       "      <td>13877.610352</td>\n",
       "      <td>3531570000</td>\n",
       "      <td>0.007844</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>675</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>13912.790039</td>\n",
       "      <td>13922.440430</td>\n",
       "      <td>13843.790039</td>\n",
       "      <td>13843.809570</td>\n",
       "      <td>13843.809570</td>\n",
       "      <td>3600250000</td>\n",
       "      <td>-0.002436</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13783.809570</td>\n",
       "      <td>13788.219727</td>\n",
       "      <td>13573.040039</td>\n",
       "      <td>13614.099609</td>\n",
       "      <td>13614.099609</td>\n",
       "      <td>4529700000</td>\n",
       "      <td>-0.017878</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>13809</td>\n",
       "      <td>240</td>\n",
       "      <td>160</td>\n",
       "      <td>14398.620117</td>\n",
       "      <td>14398.620117</td>\n",
       "      <td>14324.769531</td>\n",
       "      <td>14382.500000</td>\n",
       "      <td>14382.500000</td>\n",
       "      <td>1883780000</td>\n",
       "      <td>-0.001120</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>21767</td>\n",
       "      <td>351</td>\n",
       "      <td>309</td>\n",
       "      <td>14476.349609</td>\n",
       "      <td>14481.480469</td>\n",
       "      <td>14396.230469</td>\n",
       "      <td>14405.769531</td>\n",
       "      <td>14405.769531</td>\n",
       "      <td>3535460000</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>30067</td>\n",
       "      <td>522</td>\n",
       "      <td>359</td>\n",
       "      <td>14500.030273</td>\n",
       "      <td>14515.809570</td>\n",
       "      <td>14371.870117</td>\n",
       "      <td>14397.919922</td>\n",
       "      <td>14397.919922</td>\n",
       "      <td>3393290000</td>\n",
       "      <td>-0.000545</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>30403</td>\n",
       "      <td>542</td>\n",
       "      <td>298</td>\n",
       "      <td>14447.959961</td>\n",
       "      <td>14520.570313</td>\n",
       "      <td>14447.959961</td>\n",
       "      <td>14477.480469</td>\n",
       "      <td>14477.480469</td>\n",
       "      <td>3154850000</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>23381</td>\n",
       "      <td>405</td>\n",
       "      <td>225</td>\n",
       "      <td>14469.000000</td>\n",
       "      <td>14533.209961</td>\n",
       "      <td>14422.740234</td>\n",
       "      <td>14524.799805</td>\n",
       "      <td>14524.799805</td>\n",
       "      <td>3179040000</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>UP</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  length  positive_word_count  negative_word_count  \\\n",
       "0   2020-01-23     386                    5                   10   \n",
       "1   2020-01-27    1599                   23                   32   \n",
       "2   2020-01-28    1094                   30                   25   \n",
       "3   2020-01-29     675                    7                   18   \n",
       "4   2020-01-31     530                    0                   14   \n",
       "..         ...     ...                  ...                  ...   \n",
       "228 2020-12-24   13809                  240                  160   \n",
       "229 2020-12-28   21767                  351                  309   \n",
       "230 2020-12-29   30067                  522                  359   \n",
       "231 2020-12-30   30403                  542                  298   \n",
       "232 2020-12-31   23381                  405                  225   \n",
       "\n",
       "             Open          High           Low         Close     Adj Close  \\\n",
       "0    14064.280273  14109.589844  14003.280273  14102.040039  14102.040039   \n",
       "1    13746.629883  13826.429688  13742.009766  13769.599609  13769.599609   \n",
       "2    13812.650391  13913.589844  13798.339844  13877.610352  13877.610352   \n",
       "3    13912.790039  13922.440430  13843.790039  13843.809570  13843.809570   \n",
       "4    13783.809570  13788.219727  13573.040039  13614.099609  13614.099609   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "228  14398.620117  14398.620117  14324.769531  14382.500000  14382.500000   \n",
       "229  14476.349609  14481.480469  14396.230469  14405.769531  14405.769531   \n",
       "230  14500.030273  14515.809570  14371.870117  14397.919922  14397.919922   \n",
       "231  14447.959961  14520.570313  14447.959961  14477.480469  14477.480469   \n",
       "232  14469.000000  14533.209961  14422.740234  14524.799805  14524.799805   \n",
       "\n",
       "         Volume  Daily_return Trend  Trend_duration  negative_score  \n",
       "0    3766710000     -0.000581  DOWN               1        0.025907  \n",
       "1    3831050000     -0.014942  DOWN               3        0.020013  \n",
       "2    3531570000      0.007844    UP               1        0.022852  \n",
       "3    3600250000     -0.002436  DOWN               1        0.026667  \n",
       "4    4529700000     -0.017878  DOWN               1        0.026415  \n",
       "..          ...           ...   ...             ...             ...  \n",
       "228  1883780000     -0.001120  DOWN               1        0.011587  \n",
       "229  3535460000      0.001618    UP               1        0.014196  \n",
       "230  3393290000     -0.000545  DOWN               1        0.011940  \n",
       "231  3154850000      0.005526    UP               1        0.009802  \n",
       "232  3179040000      0.003268    UP               2        0.009623  \n",
       "\n",
       "[233 rows x 14 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_merged['negative_score'] = clean_merged['negative_word_count']/clean_merged['length']\n",
    "clean_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f895e",
   "metadata": {},
   "source": [
    "## test how many days lag have the most significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62d486e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of Daily Return with 1-day Lag: -0.2707865580513764\n",
      "Correlation of Daily Return with 2-day Lag: 0.2849232362226285\n",
      "Correlation of Daily Return with 3-day Lag: -0.02352066316820056\n",
      "Correlation of Daily Return with 4-day Lag: -0.12434942366017733\n",
      "Correlation of Daily Return with 5-day Lag: 0.1911720919820946\n"
     ]
    }
   ],
   "source": [
    "# 1-5 day correlation\n",
    "test = clean_merged\n",
    "for i in range(1, 6):\n",
    "    lagged_returns = test['Daily_return'].shift(i)\n",
    "    correlation = test['Daily_return'].corr(lagged_returns.dropna())  # Remove missing values before calculating correlation\n",
    "    print(f'Correlation of Daily Return with {i}-day Lag: {correlation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80f34352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 1 lags: AIC = -1105.5077887484867, BIC = -1095.193550821717\n",
      "Model with 2 lags: AIC = -1108.1735732550276, BIC = -1094.4386852408106\n",
      "Model with 3 lags: AIC = -1103.0973082092687, BIC = -1085.9505800644965\n",
      "Model with 4 lags: AIC = -1105.5204466522086, BIC = -1084.9707465473202\n",
      "Model with 5 lags: AIC = -1100.4613784419187, BIC = -1076.5176334470127\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "test['return_lag1'] = test['Daily_return'].shift(1)\n",
    "test['return_lag2'] = test['Daily_return'].shift(2)\n",
    "test['return_lag3'] = test['Daily_return'].shift(3)\n",
    "test['return_lag4'] = test['Daily_return'].shift(4)\n",
    "test['return_lag5'] = test['Daily_return'].shift(5)\n",
    "# Models with 1 to 5 lags\n",
    "for i in range(1, 6):\n",
    "    # Create the formula for the model\n",
    "    formula = 'Daily_return ~ negative_score + ' + ' + '.join(f'return_lag{j}' for j in range(1, i+1))\n",
    "\n",
    "    # Fit the model\n",
    "    model = smf.ols(formula=formula, data=test).fit()\n",
    "\n",
    "    # Print the AIC and BIC\n",
    "    print(f'Model with {i} lags: AIC = {model.aic}, BIC = {model.bic}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3eaf5",
   "metadata": {},
   "source": [
    "Correlation of Daily Return with 1-day Lag: -0.2707865580513764\n",
    "Correlation of Daily Return with 2-day Lag: 0.2849232362226285\n",
    "Correlation of Daily Return with 3-day Lag: -0.02352066316820056\n",
    "Correlation of Daily Return with 4-day Lag: -0.12434942366017733\n",
    "Correlation of Daily Return with 5-day Lag: 0.1911720919820946\n",
    "Model with 1 lags: AIC = -1105.5077887484867, BIC = -1095.193550821717\n",
    "Model with 2 lags: AIC = -1108.1735732550276, BIC = -1094.4386852408106\n",
    "Model with 3 lags: AIC = -1103.0973082092687, BIC = -1085.9505800644965\n",
    "Model with 4 lags: AIC = -1105.5204466522086, BIC = -1084.9707465473202\n",
    "Model with 5 lags: AIC = -1100.4613784419187, BIC = -1076.5176334470127"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11d839",
   "metadata": {},
   "source": [
    "## We can find that 2 day lag has the most significance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a6b9e3",
   "metadata": {},
   "source": [
    "# model of 1 day lag and 2 day lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ea6093be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Daily_return   R-squared:                       0.115\n",
      "Model:                            OLS   Adj. R-squared:                  0.107\n",
      "Method:                 Least Squares   F-statistic:                     14.81\n",
      "Date:                Mon, 31 Jul 2023   Prob (F-statistic):           8.98e-07\n",
      "Time:                        19:44:47   Log-Likelihood:                 560.52\n",
      "No. Observations:                 231   AIC:                            -1115.\n",
      "Df Residuals:                     228   BIC:                            -1105.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           0.0004      0.001      0.265      0.791      -0.002       0.003\n",
      "return_lag1    -0.2097      0.065     -3.246      0.001      -0.337      -0.082\n",
      "return_lag2     0.2158      0.065      3.340      0.001       0.089       0.343\n",
      "==============================================================================\n",
      "Omnibus:                       61.640   Durbin-Watson:                   2.043\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              567.920\n",
      "Skew:                          -0.712   Prob(JB):                    4.76e-124\n",
      "Kurtosis:                      10.548   Cond. No.                         51.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "##### import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = clean_merged\n",
    "\n",
    "# Assuming df is your DataFrame and 'Daily_return' and 'negative_word_count' are the columns with returns and sentiment scores respectively\n",
    "df['return_lag1'] = df['Daily_return'].shift(1)\n",
    "df['return_lag2'] = df['Daily_return'].shift(2)\n",
    "\n",
    "# Drop the missing values that were created because of the lag\n",
    "df = df.dropna()\n",
    "\n",
    "# Define your dependent variable (y) and independent variables (X)\n",
    "y = df['Daily_return']\n",
    "X = df[['return_lag1', 'return_lag2']]\n",
    "\n",
    "# Add a constant to the independent variables matrix\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ae545",
   "metadata": {},
   "source": [
    "# add sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4ff1e46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Daily_return   R-squared:                       0.130\n",
      "Model:                            OLS   Adj. R-squared:                  0.119\n",
      "Method:                 Least Squares   F-statistic:                     11.35\n",
      "Date:                Mon, 31 Jul 2023   Prob (F-statistic):           5.75e-07\n",
      "Time:                        19:44:55   Log-Likelihood:                 562.56\n",
      "No. Observations:                 231   AIC:                            -1117.\n",
      "Df Residuals:                     227   BIC:                            -1103.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.0146      0.007      2.025      0.044       0.000       0.029\n",
      "return_lag1       -0.2296      0.065     -3.536      0.000      -0.358      -0.102\n",
      "return_lag2        0.1970      0.065      3.038      0.003       0.069       0.325\n",
      "negative_score    -1.1542      0.574     -2.012      0.045      -2.285      -0.024\n",
      "==============================================================================\n",
      "Omnibus:                       56.096   Durbin-Watson:                   2.040\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              525.326\n",
      "Skew:                          -0.595   Prob(JB):                    8.45e-115\n",
      "Kurtosis:                      10.291   Cond. No.                         408.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Define your dependent variable (y) and independent variables (X)\n",
    "y = df['Daily_return']\n",
    "X = df[['return_lag1', 'return_lag2', 'negative_score']]\n",
    "\n",
    "# Add a constant to the independent variables matrix\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafe486",
   "metadata": {},
   "source": [
    "# Imaginative Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f382681b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I note that Keir Starmer has opened his accoun...</td>\n",
       "      <td>6-Apr-20</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As Covid19 makes social distancing a matter of...</td>\n",
       "      <td>6-Apr-20</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Britons will need to stay at home for weeks to...</td>\n",
       "      <td>6-Apr-20</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labourâs new leader exudes competence and id...</td>\n",
       "      <td>6-Apr-20</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHEN are news and magazinestyle programmes goi...</td>\n",
       "      <td>6-Apr-20</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body      date  length\n",
       "0  I note that Keir Starmer has opened his accoun...  6-Apr-20     270\n",
       "1  As Covid19 makes social distancing a matter of...  6-Apr-20     963\n",
       "2  Britons will need to stay at home for weeks to...  6-Apr-20     646\n",
       "3  Labourâs new leader exudes competence and id...  6-Apr-20     613\n",
       "4  WHEN are news and magazinestyle programmes goi...  6-Apr-20     102"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = pd.read_csv('raw_data/IMG_corpus/img_corpus.csv', encoding='latin-1')\n",
    "img.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ad409a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3551 entries, 0 to 3550\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   body    3243 non-null   object\n",
      " 1   date    3535 non-null   object\n",
      " 2   length  3551 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 83.4+ KB\n"
     ]
    }
   ],
   "source": [
    "img.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b7fcf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   body date  length\n",
      "123   If summer is to bring any sense of normalcy th...  NaN    1511\n",
      "500                                                 NaN  NaN       0\n",
      "501                                                 NaN  NaN       0\n",
      "1002                                                NaN  NaN       0\n",
      "1003                                                NaN  NaN       0\n",
      "1190  Stock and oil prices climbed on Monday on news...  NaN     653\n",
      "1504                                                NaN  NaN       0\n",
      "1505                                                NaN  NaN       0\n",
      "2006                                                NaN  NaN       0\n",
      "2007                                                NaN  NaN       0\n",
      "2508                                                NaN  NaN       0\n",
      "2509                                                NaN  NaN       0\n",
      "3010                                                NaN  NaN       0\n",
      "3011                                                NaN  NaN       0\n",
      "3512                                                NaN  NaN       0\n",
      "3513                                                NaN  NaN       0\n"
     ]
    }
   ],
   "source": [
    "# Show rows where 'date' or 'length' is null\n",
    "missing_dates_or_lengths = img[img['date'].isnull() | img['length'].isnull()]\n",
    "print(missing_dates_or_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b3e0bcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I note that Keir Starmer has opened his accoun...</td>\n",
       "      <td>6-Apr-20</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As Covid19 makes social distancing a matter of...</td>\n",
       "      <td>6-Apr-20</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Britons will need to stay at home for weeks to...</td>\n",
       "      <td>6-Apr-20</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labourâs new leader exudes competence and id...</td>\n",
       "      <td>6-Apr-20</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHEN are news and magazinestyle programmes goi...</td>\n",
       "      <td>6-Apr-20</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>Thereâs no sign that ministers will use the ...</td>\n",
       "      <td>27-Dec-20</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>On this last Sunday of 2020 we reflect on what...</td>\n",
       "      <td>27-Dec-20</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>sir  I thought your Leading Article December 2...</td>\n",
       "      <td>27-Dec-20</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549</th>\n",
       "      <td>sir  I have been following the discussion abou...</td>\n",
       "      <td>27-Dec-20</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>The House of Commons has been the beating hear...</td>\n",
       "      <td>26-Dec-20</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3492 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body       date  length\n",
       "0     I note that Keir Starmer has opened his accoun...   6-Apr-20     270\n",
       "1     As Covid19 makes social distancing a matter of...   6-Apr-20     963\n",
       "2     Britons will need to stay at home for weeks to...   6-Apr-20     646\n",
       "3     Labourâs new leader exudes competence and id...   6-Apr-20     613\n",
       "4     WHEN are news and magazinestyle programmes goi...   6-Apr-20     102\n",
       "...                                                 ...        ...     ...\n",
       "3546  Thereâs no sign that ministers will use the ...  27-Dec-20    1065\n",
       "3547  On this last Sunday of 2020 we reflect on what...  27-Dec-20     831\n",
       "3548  sir  I thought your Leading Article December 2...  27-Dec-20     165\n",
       "3549  sir  I have been following the discussion abou...  27-Dec-20     355\n",
       "3550  The House of Commons has been the beating hear...  26-Dec-20     643\n",
       "\n",
       "[3492 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = img\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def is_date(string):\n",
    "    try: \n",
    "        parse(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Convert all dates to strings before trying to parse them\n",
    "img1['date'] = img1['date'].astype(str)\n",
    "\n",
    "# Create a boolean mask for the rows with good dates\n",
    "mask = img1['date'].apply(is_date)\n",
    "\n",
    "# Keep only the rows with good dates (and drop the rows with bad dates)\n",
    "img1 = img1[mask]\n",
    "img1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf30b212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20315\\AppData\\Local\\Temp\\ipykernel_17168\\2742660590.py:5: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  return pd.datetime.strptime(date, fmt)\n",
      "C:\\Users\\20315\\AppData\\Local\\Temp\\ipykernel_17168\\2742660590.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  img1['date'] = img1['date'].apply(parse_dates)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I note that Keir Starmer has opened his accoun...</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As Covid19 makes social distancing a matter of...</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Britons will need to stay at home for weeks to...</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labourâs new leader exudes competence and id...</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHEN are news and magazinestyle programmes goi...</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       date  length\n",
       "0  I note that Keir Starmer has opened his accoun... 2020-04-06     270\n",
       "1  As Covid19 makes social distancing a matter of... 2020-04-06     963\n",
       "2  Britons will need to stay at home for weeks to... 2020-04-06     646\n",
       "3  Labourâs new leader exudes competence and id... 2020-04-06     613\n",
       "4  WHEN are news and magazinestyle programmes goi... 2020-04-06     102"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function to handle multiple date formats\n",
    "def parse_dates(date):\n",
    "    for fmt in ('%b%d,%Y', '%d-%b-%y'):\n",
    "        try:\n",
    "            return pd.datetime.strptime(date, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return np.nan\n",
    "\n",
    "# Apply the function to the date column\n",
    "img1['date'] = img1['date'].apply(parse_dates)\n",
    "\n",
    "\n",
    "img1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c98c081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3492 entries, 0 to 3550\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   body    3198 non-null   object        \n",
      " 1   date    3488 non-null   datetime64[ns]\n",
      " 2   length  3492 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 109.1+ KB\n"
     ]
    }
   ],
   "source": [
    "img1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "15919530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I note that Keir Starmer has opened his accoun...</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As Covid19 makes social distancing a matter of...</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Britons will need to stay at home for weeks to...</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labourâs new leader exudes competence and id...</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHEN are news and magazinestyle programmes goi...</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       date  length\n",
       "0  I note that Keir Starmer has opened his accoun... 2020-04-06     270\n",
       "1  As Covid19 makes social distancing a matter of... 2020-04-06     963\n",
       "2  Britons will need to stay at home for weeks to... 2020-04-06     646\n",
       "3  Labourâs new leader exudes competence and id... 2020-04-06     613\n",
       "4  WHEN are news and magazinestyle programmes goi... 2020-04-06     102"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = img1.dropna(subset=['date', 'length','body'])\n",
    "img1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64df621a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The novel coronavirus has killed at least 425 ...</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The novel coronavirus has killed at least 425 ...</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In just over a month the coronavirus outbreak ...</td>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The World Health Organization WHO still hasnt ...</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir  The Schengen Agreement is the perfect pol...</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       date  length\n",
       "0  The novel coronavirus has killed at least 425 ... 2020-02-04     281\n",
       "1  The novel coronavirus has killed at least 425 ... 2020-02-05     297\n",
       "2  In just over a month the coronavirus outbreak ... 2020-02-18     470\n",
       "3  The World Health Organization WHO still hasnt ... 2020-02-25     747\n",
       "4  sir  The Schengen Agreement is the perfect pol... 2020-02-25     376"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by date in ascending order\n",
    "img1 = img1.sort_values(by='date')\n",
    "img1 = img1.reset_index(drop=True)\n",
    "# Check the result\n",
    "img1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6abe8aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1['positive_word_count'] = img1['body'].apply(count_positive_words)\n",
    "# Add a new column 'negative_word_count' to the DataFrame\n",
    "img1['negative_word_count'] = img1['body'].apply(count_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6079d9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3194 entries, 0 to 3193\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   body                 3194 non-null   object        \n",
      " 1   date                 3194 non-null   datetime64[ns]\n",
      " 2   length               3194 non-null   int64         \n",
      " 3   positive_word_count  3194 non-null   int64         \n",
      " 4   negative_word_count  3194 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(3), object(1)\n",
      "memory usage: 124.9+ KB\n"
     ]
    }
   ],
   "source": [
    "img1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a8bde672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>281</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>297</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>470</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>747</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>376</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  length  positive_word_count  negative_word_count\n",
       "0 2020-02-04     281                   12                   11\n",
       "1 2020-02-05     297                   13                   11\n",
       "2 2020-02-18     470                    8                   18\n",
       "3 2020-02-25     747                    8                   11\n",
       "4 2020-02-25     376                    8                    7"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['body']\n",
    "img1.drop(columns=columns_to_drop, inplace=True)\n",
    "img1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2eb1af64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>281</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>297</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>470</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>1927</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>2858</td>\n",
       "      <td>53</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  length  positive_word_count  negative_word_count\n",
       "0 2020-02-04     281                   12                   11\n",
       "1 2020-02-05     297                   13                   11\n",
       "2 2020-02-18     470                    8                   18\n",
       "3 2020-02-25    1927                   24                   30\n",
       "4 2020-02-28    2858                   53                   59"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_grouped = img1.groupby('date').agg({\n",
    "    'length': 'sum',\n",
    "    'positive_word_count': 'sum',\n",
    "    'negative_word_count': 'sum'\n",
    "}).reset_index()\n",
    "img_grouped.to_csv('img_cleaned.csv', index=False)\n",
    "img_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e6ffe8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_grouped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4152\\3263355197.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_merged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_grouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg_merged\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'negative_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_merged\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'negative_word_count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mimg_merged\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg_merged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_grouped' is not defined"
     ]
    }
   ],
   "source": [
    "img_merged = img_grouped.merge(ny, on='date', how='inner')\n",
    "img_merged['negative_score'] = img_merged['negative_word_count']/img_merged['length']\n",
    "img_merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "024d9a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Daily_return   R-squared:                       0.120\n",
      "Model:                            OLS   Adj. R-squared:                  0.111\n",
      "Method:                 Least Squares   F-statistic:                     14.46\n",
      "Date:                Mon, 31 Jul 2023   Prob (F-statistic):           1.30e-06\n",
      "Time:                        19:04:02   Log-Likelihood:                 520.45\n",
      "No. Observations:                 216   AIC:                            -1035.\n",
      "Df Residuals:                     213   BIC:                            -1025.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           0.0008      0.001      0.544      0.587      -0.002       0.004\n",
      "return_lag1    -0.2301      0.067     -3.431      0.001      -0.362      -0.098\n",
      "return_lag2     0.2001      0.067      2.986      0.003       0.068       0.332\n",
      "==============================================================================\n",
      "Omnibus:                       61.257   Durbin-Watson:                   2.030\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              528.444\n",
      "Skew:                          -0.789   Prob(JB):                    1.78e-115\n",
      "Kurtosis:                      10.498   Cond. No.                         51.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "##### import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = img_merged\n",
    "\n",
    "# Assuming df is your DataFrame and 'Daily_return' and 'negative_word_count' are the columns with returns and sentiment scores respectively\n",
    "df['return_lag1'] = df['Daily_return'].shift(1)\n",
    "df['return_lag2'] = df['Daily_return'].shift(2)\n",
    "\n",
    "# Drop the missing values that were created because of the lag\n",
    "df = df.dropna()\n",
    "\n",
    "# Define your dependent variable (y) and independent variables (X)\n",
    "y = df['Daily_return']\n",
    "X = df[['return_lag1', 'return_lag2']]\n",
    "\n",
    "# Add a constant to the independent variables matrix\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "37a051a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Daily_return   R-squared:                       0.120\n",
      "Model:                            OLS   Adj. R-squared:                  0.107\n",
      "Method:                 Least Squares   F-statistic:                     9.627\n",
      "Date:                Mon, 31 Jul 2023   Prob (F-statistic):           5.50e-06\n",
      "Time:                        19:04:08   Log-Likelihood:                 520.50\n",
      "No. Observations:                 216   AIC:                            -1033.\n",
      "Df Residuals:                     212   BIC:                            -1019.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.0027      0.006      0.419      0.675      -0.010       0.015\n",
      "return_lag1       -0.2319      0.067     -3.437      0.001      -0.365      -0.099\n",
      "return_lag2        0.1974      0.068      2.913      0.004       0.064       0.331\n",
      "negative_score    -0.1077      0.359     -0.300      0.765      -0.816       0.601\n",
      "==============================================================================\n",
      "Omnibus:                       60.150   Durbin-Watson:                   2.036\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              523.438\n",
      "Skew:                          -0.764   Prob(JB):                    2.17e-114\n",
      "Kurtosis:                      10.472   Cond. No.                         241.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Define your dependent variable (y) and independent variables (X)\n",
    "y = df['Daily_return']\n",
    "X = df[['return_lag1', 'return_lag2', 'negative_score']]\n",
    "\n",
    "# Add a constant to the independent variables matrix\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbaece1",
   "metadata": {},
   "source": [
    "# Full Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f1d406e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 645 entries, 0 to 311\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   date                 645 non-null    datetime64[ns]\n",
      " 1   length               645 non-null    int64         \n",
      " 2   positive_word_count  645 non-null    int64         \n",
      " 3   negative_word_count  645 non-null    int64         \n",
      "dtypes: datetime64[ns](1), int64(3)\n",
      "memory usage: 25.2 KB\n"
     ]
    }
   ],
   "source": [
    "full = pd.concat([clean_grouped, img_grouped])\n",
    "full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "66d99c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334 entries, 0 to 333\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   date                 334 non-null    datetime64[ns]\n",
      " 1   length               334 non-null    int64         \n",
      " 2   positive_word_count  334 non-null    int64         \n",
      " 3   negative_word_count  334 non-null    int64         \n",
      "dtypes: datetime64[ns](1), int64(3)\n",
      "memory usage: 10.6 KB\n"
     ]
    }
   ],
   "source": [
    "full_grouped = full.groupby('date').agg({\n",
    "    'length': 'sum',\n",
    "    'positive_word_count': 'sum',\n",
    "    'negative_word_count': 'sum'\n",
    "}).reset_index()\n",
    "full_grouped.to_csv('full_grouped.csv', index=False)\n",
    "full_grouped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c86764e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_return</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Trend_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>386</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>14064.280273</td>\n",
       "      <td>14109.589844</td>\n",
       "      <td>14003.280273</td>\n",
       "      <td>14102.040039</td>\n",
       "      <td>14102.040039</td>\n",
       "      <td>3766710000</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>1599</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>13746.629883</td>\n",
       "      <td>13826.429688</td>\n",
       "      <td>13742.009766</td>\n",
       "      <td>13769.599609</td>\n",
       "      <td>13769.599609</td>\n",
       "      <td>3831050000</td>\n",
       "      <td>-0.014942</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1094</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>13812.650391</td>\n",
       "      <td>13913.589844</td>\n",
       "      <td>13798.339844</td>\n",
       "      <td>13877.610352</td>\n",
       "      <td>13877.610352</td>\n",
       "      <td>3531570000</td>\n",
       "      <td>0.007844</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>675</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>13912.790039</td>\n",
       "      <td>13922.440430</td>\n",
       "      <td>13843.790039</td>\n",
       "      <td>13843.809570</td>\n",
       "      <td>13843.809570</td>\n",
       "      <td>3600250000</td>\n",
       "      <td>-0.002436</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13783.809570</td>\n",
       "      <td>13788.219727</td>\n",
       "      <td>13573.040039</td>\n",
       "      <td>13614.099609</td>\n",
       "      <td>13614.099609</td>\n",
       "      <td>4529700000</td>\n",
       "      <td>-0.017878</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  length  positive_word_count  negative_word_count          Open  \\\n",
       "0 2020-01-23     386                    5                   10  14064.280273   \n",
       "1 2020-01-27    1599                   23                   32  13746.629883   \n",
       "2 2020-01-28    1094                   30                   25  13812.650391   \n",
       "3 2020-01-29     675                    7                   18  13912.790039   \n",
       "4 2020-01-31     530                    0                   14  13783.809570   \n",
       "\n",
       "           High           Low         Close     Adj Close      Volume  \\\n",
       "0  14109.589844  14003.280273  14102.040039  14102.040039  3766710000   \n",
       "1  13826.429688  13742.009766  13769.599609  13769.599609  3831050000   \n",
       "2  13913.589844  13798.339844  13877.610352  13877.610352  3531570000   \n",
       "3  13922.440430  13843.790039  13843.809570  13843.809570  3600250000   \n",
       "4  13788.219727  13573.040039  13614.099609  13614.099609  4529700000   \n",
       "\n",
       "   Daily_return Trend  Trend_duration  \n",
       "0     -0.000581  DOWN               1  \n",
       "1     -0.014942  DOWN               3  \n",
       "2      0.007844    UP               1  \n",
       "3     -0.002436  DOWN               1  \n",
       "4     -0.017878  DOWN               1  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merged = full_grouped.merge(ny, on='date', how='inner')\n",
    "full_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "eda44f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 234 entries, 0 to 233\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   date                 234 non-null    datetime64[ns]\n",
      " 1   length               234 non-null    int64         \n",
      " 2   positive_word_count  234 non-null    int64         \n",
      " 3   negative_word_count  234 non-null    int64         \n",
      " 4   Open                 234 non-null    float64       \n",
      " 5   High                 234 non-null    float64       \n",
      " 6   Low                  234 non-null    float64       \n",
      " 7   Close                234 non-null    float64       \n",
      " 8   Adj Close            234 non-null    float64       \n",
      " 9   Volume               234 non-null    int64         \n",
      " 10  Daily_return         234 non-null    float64       \n",
      " 11  Trend                234 non-null    object        \n",
      " 12  Trend_duration       234 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(6), int64(5), object(1)\n",
      "memory usage: 25.6+ KB\n"
     ]
    }
   ],
   "source": [
    "full_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f6aead83",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merged['negative_score'] = full_merged['negative_word_count']/full_merged['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c07995a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Daily_return   R-squared:                       0.114\n",
      "Model:                            OLS   Adj. R-squared:                  0.106\n",
      "Method:                 Least Squares   F-statistic:                     14.68\n",
      "Date:                Mon, 31 Jul 2023   Prob (F-statistic):           1.00e-06\n",
      "Time:                        19:53:38   Log-Likelihood:                 563.10\n",
      "No. Observations:                 232   AIC:                            -1120.\n",
      "Df Residuals:                     229   BIC:                            -1110.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           0.0004      0.001      0.306      0.760      -0.002       0.003\n",
      "return_lag1    -0.2091      0.064     -3.243      0.001      -0.336      -0.082\n",
      "return_lag2     0.2142      0.064      3.322      0.001       0.087       0.341\n",
      "==============================================================================\n",
      "Omnibus:                       61.985   Durbin-Watson:                   2.041\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              568.325\n",
      "Skew:                          -0.716   Prob(JB):                    3.89e-124\n",
      "Kurtosis:                      10.533   Cond. No.                         51.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "##### import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = full_merged\n",
    "\n",
    "# Assuming df is your DataFrame and 'Daily_return' and 'negative_word_count' are the columns with returns and sentiment scores respectively\n",
    "df['return_lag1'] = df['Daily_return'].shift(1)\n",
    "df['return_lag2'] = df['Daily_return'].shift(2)\n",
    "\n",
    "# Drop the missing values that were created because of the lag\n",
    "df = df.dropna()\n",
    "\n",
    "# Define your dependent variable (y) and independent variables (X)\n",
    "y = df['Daily_return']\n",
    "X = df[['return_lag1', 'return_lag2']]\n",
    "\n",
    "# Add a constant to the independent variables matrix\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1d649bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Daily_return   R-squared:                       0.120\n",
      "Model:                            OLS   Adj. R-squared:                  0.109\n",
      "Method:                 Least Squares   F-statistic:                     10.41\n",
      "Date:                Mon, 31 Jul 2023   Prob (F-statistic):           1.90e-06\n",
      "Time:                        19:53:49   Log-Likelihood:                 564.00\n",
      "No. Observations:                 232   AIC:                            -1120.\n",
      "Df Residuals:                     228   BIC:                            -1106.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.0088      0.006      1.368      0.173      -0.004       0.021\n",
      "return_lag1       -0.2230      0.065     -3.420      0.001      -0.352      -0.095\n",
      "return_lag2        0.2018      0.065      3.102      0.002       0.074       0.330\n",
      "negative_score    -0.6357      0.477     -1.333      0.184      -1.575       0.304\n",
      "==============================================================================\n",
      "Omnibus:                       57.006   Durbin-Watson:                   2.036\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              519.163\n",
      "Skew:                          -0.621   Prob(JB):                    1.84e-113\n",
      "Kurtosis:                      10.222   Cond. No.                         339.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Define your dependent variable (y) and independent variables (X)\n",
    "y = df['Daily_return']\n",
    "X = df[['return_lag1', 'return_lag2', 'negative_score']]\n",
    "\n",
    "# Add a constant to the independent variables matrix\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.O\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
